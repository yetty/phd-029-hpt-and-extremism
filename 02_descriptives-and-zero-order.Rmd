---
title: "Descriptives & Zero-order associations — HPT (Czech data)"
subtitle: "Means/SDs, distributions, correlations, and school/class variation"
author: "HPT and Extremism project"
date: "`r format(Sys.Date())`"
always_allow_html: true
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    toc_depth: 3
    keep_tex: true
    
  md_document:
    variant: markdown
    preserve_yaml: false
    toc: false

# global chunk options
knitr:
  opts_chunk:
    dev: "png"          # ensures image files are written
    fig.path: "figures/" # directory for external images
    dpi: 300


fontsize: 10pt
geometry:
  - landscape
  - margin=0.7in

header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \setlength{\LTcapwidth}{\textwidth}
---

# Purpose

This file establishes transparent baseline patterns—distributions, scale descriptives, zero-order correlations, and between-group variation—before any modeling. It follows the HPT framework (POP/ROA/CONT) and scoring conventions used in prior work, so higher HPT scores reflect better contextualization/agent-sensitive reasoning; FR-LF and KSA reflect ideological/authoritarian agreement; SDR reflects social-desirability responding. These descriptives document the empirical landscape your hypotheses build on.
*Interpretation cheatsheet appears under each table/figure.*

```{r,setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", fig.width = 8, fig.height = 5, out.width = "95%")
```

## 1) Data & packages

```{r,packages}
# Core
library(dplyr); library(stringr); library(tidyr); library(purrr); library(readxl)
# Tables & plots
library(knitr); library(kableExtra); library(ggplot2); library(scales)
# Correlations
library(psych);           # corr.test
# Multilevel & ICC
library(lme4);            # lmer
suppressPackageStartupMessages(library(performance)) # icc()

theme_set(theme_minimal(base_size = 11))
```

```{r,load-data}
# Load the dataset created in 00_data-preparation
load("normalised_responses.RData")
stopifnot(exists("normalised_responses"))

all_data <- normalised_responses

# Ensure factors as in codebook
all_data <- all_data %>%
  mutate(
    school_id    = as.factor(school_id),
    class_label  = as.factor(class_label),
    school_level = as.factor(school_level),
    school_type  = as.factor(school_type),
    region       = as.factor(region),
    gender       = as.factor(gender)
  )
```

## 2) Scoring: constructs & subscores

```{r,score-scales}
# Convenience scorer: mean across items with minimum answered requirement
scale_mean <- function(df, items, min_n = ceiling(length(items)/2), na.rm = TRUE) {
  x <- df[, items]
  ok <- rowSums(!is.na(x)) >= min_n
  out <- rowMeans(x, na.rm = na.rm)
  out[!ok] <- NA_real_
  out
}

# HPT (1-4): subscores and total (average so all stay on 1-4)
hpt_pop_items  <- c("POP1","POP2","POP3")
hpt_roa_items  <- c("ROA1","ROA2","ROA3")
hpt_cont_items <- c("CONT1","CONT2","CONT3")

# Knowledge (0-6 correct)
kn_items <- paste0("KN", 1:6)

# FR-LF mini (1-5 Likert): RD1-3 + NS1-3
frlf_rd <- paste0("RD", 1:3)
frlf_ns <- paste0("NS", 1:3)

# KSA-3 authoritarianism (1-5 Likert): 9 items
ksa_items <- c(paste0("A",1:3), paste0("U",1:3), paste0("K",1:3))

# SDR-5 (1-5 Likert): SDR2-SDR4 already reversed in the dataset per codebook
sdr_items <- paste0("SDR", 1:5)

dat <- all_data %>%
  mutate(
    HPT_POP  = scale_mean(., hpt_pop_items,  min_n = 2),
    HPT_ROA  = scale_mean(., hpt_roa_items,  min_n = 2),
    HPT_CONT = scale_mean(., hpt_cont_items, min_n = 2),
    HPT_TOTAL = scale_mean(., c(hpt_pop_items, hpt_roa_items, hpt_cont_items), min_n = 5),
    KN_TOTAL  = rowSums(select(., all_of(kn_items)), na.rm = TRUE),
    FRLF_RD   = scale_mean(., frlf_rd, min_n = 2),
    FRLF_NS   = scale_mean(., frlf_ns, min_n = 2),
    FRLF_MINI = scale_mean(., c(frlf_rd, frlf_ns), min_n = 4),
    KSA_TOTAL = scale_mean(., ksa_items, min_n = 7),
    SDR_TOTAL = scale_mean(., sdr_items, min_n = 4)
  )
```

> **How to read:**
> • **HPT**: 1-4, higher = better fit of reasoning to historical context/agent constraints (POP/ROA/CONT per instrument).
> • **Knowledge (KN_TOTAL)**: 0-6 correct.
> • **FR-LF mini (FRLF_MINI; plus RD, NS)**: 1-5, higher = stronger endorsement (e.g., leader/one-party; NS relativization).
> • **KSA-3 (KSA_TOTAL)**: 1-5, higher = stronger authoritarianism.
> • **SDR_TOTAL**: 1-5, higher = stronger social desirability response tendency.
> Variable names and coding follow the project codebook.

## 3) Sample overview

```{r,sample-overview}
vars_context <- c("school_id","class_label","school_level","school_type","region","gender","history_grade")
n_raw <- nrow(all_data); n_anal <- nrow(dat)

kable(data.frame(
  N_raw = n_raw,
  N_after_scoring = n_anal,
  classes = dplyr::n_distinct(dat$class_label),
  schools = dplyr::n_distinct(dat$school_id)
), caption = "Sample counters (after loading and scoring).") %>%
  kable_styling(full_width = FALSE)
```

## 4) Descriptives (means, SDs, n, range)

```{r,descriptives}
desc_vars <- c("HPT_POP","HPT_ROA","HPT_CONT","HPT_TOTAL",
               "KN_TOTAL","FRLF_RD","FRLF_NS","FRLF_MINI",
               "KSA_TOTAL","SDR_TOTAL")

desc_tbl <- dat %>%
  summarise(across(all_of(desc_vars),
                   list(n = ~sum(!is.na(.)),
                        mean = ~mean(., na.rm=TRUE),
                        sd = ~sd(., na.rm=TRUE),
                        min = ~min(., na.rm=TRUE),
                        max = ~max(., na.rm=TRUE)))) %>%
  pivot_longer(everything(),
               names_to = c("variable",".value"),
               names_pattern = "([^_]+_[^_]+|[^_]+)_(n|mean|sd|min|max)")

# Keep original order
desc_tbl$variable <- factor(desc_tbl$variable, levels = desc_vars)

kable(desc_tbl[order(desc_tbl$variable),], booktabs = TRUE, digits = 2,
      caption = "Scale descriptives (student-level).") %>%
  kable_styling(latex_options = c("striped","hold_position"), full_width = FALSE)
```

> **Interpretation:** HPT scales should center above 2.5 if students generally avoid presentism and contextualize; FR-LF/KSA are not “good/bad” in isolation but provide ideological context for later modeling; SDR alerts to response bias.

## 5) Distributions (histograms, same axes where possible)

```{r,hists, fig.height=7}
long_scales <- dat %>%
  select(all_of(desc_vars)) %>%
  pivot_longer(everything(), names_to = "scale", values_to = "value")

ggplot(long_scales, aes(x = value)) +
  geom_histogram(bins = 20) +
  facet_wrap(~scale, scales = "free", ncol = 3) +
  labs(title = "Distributions of scales", x = "Score", y = "Count")
```

> **Interpretation:** Watch for spikes at bounds (e.g., KN at 0 or max), floor/ceiling on FR-LF/KSA, and skew in HPT subscores—useful cues for later transformation or robust modeling.

## 6) Zero-order correlations (student level)

```{r,correlations}
corr_df <- dat %>% select(all_of(desc_vars)) %>% drop_na()
ct <- psych::corr.test(corr_df, use = "pairwise")
round(ct$r, 2)
```

```{r,cor-table}
corr_tab <- as.data.frame(round(ct$r, 2))
corr_tab$Var1 <- rownames(corr_tab)
corr_tab <- corr_tab %>% relocate(Var1)

kable(corr_tab, booktabs = TRUE, caption = "Zero-order Pearson correlations among constructs (pairwise).") %>%
  kable_styling(latex_options = c("hold_position"))
```

> **Interpretation:** Correlations locate broad relationships your hypotheses rely on. For example, if **FRLF_MINI** correlates positively with **HPT_CONT**/**HPT_TOTAL**, this suggests possible ideological alignment inflating contextualization—an effect to test with controls in models (knowledge, SDR) and with item-level checks later.

## 7) Between-group variation: school/class ICCs

We estimate the variance attributable to schools and classes with random-intercept models. ICC ≈ proportion of total variance that is between clusters.

```{r,icc-funs}
# --- Robust ICC helpers (replace previous version) ---

# Safely pull ICC_adjusted (fallback to ICC or first numeric) for different object types
get_icc_value <- function(ic) {
  # ic can be data.frame/tibble, list, or numeric
  if (is.null(ic)) return(NA_real_)
  if (is.data.frame(ic)) {
    # new performance::icc often returns a data.frame with ICC and ICC_adjusted
    if ("ICC_adjusted" %in% names(ic)) return(suppressWarnings(as.numeric(ic$ICC_adjusted[1])))
    if ("ICC" %in% names(ic))          return(suppressWarnings(as.numeric(ic$ICC[1])))
    # else, first numeric column
    num_cols <- which(vapply(ic, is.numeric, logical(1)))
    if (length(num_cols)) return(as.numeric(ic[[ num_cols[1] ]][1]))
    return(NA_real_)
  }
  if (is.list(ic)) {
    if (!is.null(ic$ICC_adjusted)) return(suppressWarnings(as.numeric(ic$ICC_adjusted)))
    if (!is.null(ic$ICC))          return(suppressWarnings(as.numeric(ic$ICC)))
    # first numeric element
    nums <- unlist(ic[ vapply(ic, is.numeric, logical(1)) ], use.names = FALSE)
    if (length(nums)) return(as.numeric(nums[1]))
    return(NA_real_)
  }
  if (is.atomic(ic) && is.numeric(ic)) return(as.numeric(ic[1]))
  NA_real_
}

fit_icc <- function(v) {
  # guard: need some variance and at least 2 clusters
  if (!v %in% names(dat)) return(NULL)
  f_cls <- as.formula(paste0(v, " ~ 1 + (1|school_id/class_label)"))
  f_sch <- as.formula(paste0(v, " ~ 1 + (1|school_id)"))
  list(
    class_in_school = tryCatch(lme4::lmer(f_cls, data = dat, REML = TRUE, na.action = na.omit),
                               error = function(e) NULL),
    school_only     = tryCatch(lme4::lmer(f_sch, data = dat, REML = TRUE, na.action = na.omit),
                               error = function(e) NULL)
  )
}

extract_icc <- function(fm) {
  if (is.null(fm)) return(list(ICC = NA_real_, N = NA_integer_, clusters = NA_integer_))
  # Try ICC; handle different output types
  ic <- tryCatch(performance::icc(fm), error = function(e) NULL)
  icc_val <- get_icc_value(ic)
  # Sample size and cluster count
  N <- tryCatch(nobs(fm), error = function(e) NA_integer_)
  # Number of levels of the *first* grouping factor in the model
  clusters <- tryCatch({
    fl <- lme4::getME(fm, "flist")
    length(levels(fl[[1]]))
  }, error = function(e) NA_integer_)
  list(ICC = icc_val, N = N, clusters = clusters)
}

targets <- c("HPT_TOTAL","HPT_POP","HPT_ROA","HPT_CONT",
             "FRLF_MINI","KSA_TOTAL","KN_TOTAL","SDR_TOTAL")

icc_rows <- purrr::map(targets, function(sc) {
  mods <- fit_icc(sc)
  # extract once per model
  cls <- extract_icc(mods$class_in_school)
  sch <- extract_icc(mods$school_only)
  data.frame(
    scale = sc,
    ICC_class_in_school = round(cls$ICC, 3),
    N_class_in_school   = as.integer(cls$N),
    clusters_classes    = as.integer(cls$clusters),
    ICC_school_only     = round(sch$ICC, 3),
    N_school_only       = as.integer(sch$N),
    clusters_schools    = as.integer(sch$clusters)
  )
})
icc_res <- dplyr::bind_rows(icc_rows)
```

```{r,icc-table}
kable(icc_res, booktabs = TRUE,
      caption = "Intraclass correlations (ICCs): class (nested in school) and school.") %>%
  kable_styling(latex_options = c("striped","hold_position"), full_width = FALSE)
```

> **Interpretation:**
> • **ICC ~ 0.00-0.05** → little clustering (ordinary regression OK).
> • **ICC ~ 0.05-0.15** → modest clustering; use cluster-robust SE or multilevel models.
> • **ICC > 0.15** → strong clustering; multilevel modeling recommended.
> Compare **HPT** vs **FR-LF/KSA**: larger ICCs for ideology might reflect school milieu; larger ICCs for HPT may signal classroom task/context effects.

## 8) Quick sanity plots by class/school (optional)

```{r,group-plots, fig.height=7}
p1 <- dat %>%
  group_by(school_id, class_label) %>%
  summarise(n = n(),
            HPT_TOTAL = mean(HPT_TOTAL, na.rm=TRUE),
            FRLF_MINI = mean(FRLF_MINI, na.rm=TRUE),
            .groups = "drop") %>%
  pivot_longer(c(HPT_TOTAL, FRLF_MINI), names_to="scale", values_to="mean") %>%
  ggplot(aes(x = reorder(class_label, mean), y = mean)) +
  geom_point() +
  facet_wrap(scale ~ school_id, scales = "free_y") +
  coord_flip() +
  labs(x = "Class", y = "Class mean", title = "Class means within schools (HPT vs FR-LF)")

p1
```

> **Interpretation:** Visual check for unusually high/low classes can inform later sensitivity checks (e.g., re-running models without extreme classes).

## 9) Reproducibility appendix

```{r,session-info}
sessionInfo()
```

---

### Notes & interpretation pointers

* **HPT scales (1-4):** Higher indicates better contextualization/agent-sensitive reasoning—consistent with the three-part structure (POP/ROA/CONT) used in prior validation work. Consider that ideological alignment can mimic contextualization; correlations here are descriptive only and motivate the multilevel models planned in the main analysis.
* **FR-LF mini (1-5):** Short right-wing authoritarian/Nazi relativization composite; higher = stronger endorsement. Use primarily as a predictor/covariate and for DIF checks later.
* **Knowledge:** Treat as a covariate; it often shows small but non-zero links to HPT.
* **SDR:** Use to check attenuation/amplification of sensitive attitudes.