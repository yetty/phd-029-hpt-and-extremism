---
title: "Sensitivity analyses — HPT (Czech data)"
subtitle: "Robustness checks for scoring, ideology operationalisation, exclusions, and random-slopes"
author: "HPT and Extremism project"
date: "`r format(Sys.Date())`"
always_allow_html: true
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    toc_depth: 3
    keep_tex: true
    
  md_document:
    variant: markdown
    preserve_yaml: false
    toc: false

# global chunk options
knitr:
  opts_chunk:
    dev: "png"          # ensures image files are written
    fig.path: "figures/" # directory for external images
    dpi: 300

fontsize: 10pt
geometry:
  - landscape
  - margin=0.7in

header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \setlength{\LTcapwidth}{\textwidth}
---

# Purpose and scope

This file documents **exploratory robustness checks** of our main results. We vary how HPT is scored, how ideology is operationalised, which observations are included, and whether class-level **random slopes** are needed. The goal is to see if substantive conclusions survive reasonable perturbations—**not** to hunt for significance.

HPT scoring follows the Hartmann–Hasselhorn / Huijgen instrument logic; note earlier reports that ROA items can behave inconsistently across samples, motivating ROA-free alternatives here.  We also leverage the FR-LF dimensions RD and NS for ideology variants, aligned with the codebook of our dataset.  These analyses correspond to the “contamination” checks pre-registered in the project snapshot. 

## Setup
```{r,setup, message=FALSE, warning=FALSE}
# Core packages
library(tidyverse)
library(lme4)
library(lmerTest)
library(broom)
library(broom.mixed)
library(performance)
library(gt)
library(glue)

# Nice printing
theme_set(theme_bw())
```

## Data

```{r,load-data}
# Load the dataset created in 00_data-preparation
load("normalised_responses.RData")
stopifnot(exists("normalised_responses"))
dat_raw <- normalised_responses
```

**How to read variables.** Variable names and coding (KN, POP/ROA/CONT, RD/NS, KSA facets, SDR) are defined in the project codebook and used verbatim here. 


# 1. Scoring variants for HPT

**Why:** In prior literature, POP and CONT often form one factor, while ROA can be unstable (e.g., ROA1 cross-loads in some samples). We therefore compare the **original 9-item average** with **ROA-free** and **problem-item-free** scores. 

```{r,hpt-scores}
dat <- dat_raw %>%
  mutate(
    # Per codebook, POP/ROA/CONT are coded 1–4 (higher = better fit). :contentReference[oaicite:5]{index=5}
    HPT_total_9   = rowMeans(across(c(POP1:POP3, ROA1:ROA3, CONT1:CONT3)), na.rm = TRUE),
    HPT_total_6   = rowMeans(across(c(POP1:POP3, CONT1:CONT3)), na.rm = TRUE),           # exclude all ROA
    HPT_total_8   = rowMeans(across(c(POP1:POP3, ROA2:ROA3, CONT1:CONT3)), na.rm = TRUE) # drop ROA1 only
  )
```

### Descriptives

```{r,hpt-desc}
hpt_desc <- dat %>%
  summarise(
    `9-item (POP+ROA+CONT)` = mean(HPT_total_9,  na.rm=TRUE),
    `8-item (drop ROA1)`     = mean(HPT_total_8,  na.rm=TRUE),
    `6-item (drop all ROA)`  = mean(HPT_total_6,  na.rm=TRUE)
  ) %>% pivot_longer(everything(), names_to="Score", values_to="Mean")

gt(hpt_desc) %>%
  fmt_number(columns=Mean, decimals=2) %>%
  tab_header(title="HPT scoring variants — means (higher = better)")
```

**Interpretation.** If the **rankings of groups/effects** are stable across these scores, conclusions do not hinge on ROA behaviour. If results flip only when ROA is included, they are **fragile** and likely influenced by ROA idiosyncrasies noted in earlier work. 

---

# 2. Ideology operationalisations

**Why:** FR-LF defines six dimensions; we focus on **RD (right-authoritarian rule)** and **NS (Nazi relativisation)**. We test (a) **NS-only**, (b) **RD+NS combined** (FR-LF mini), and (c) **KSA-3** authoritarianism (total and facets). 

```{r,ideology-scores}
dat <- dat %>%
  mutate(
    KN_total   = rowSums(across(KN1:KN6), na.rm = TRUE),        # knowledge mini-test
    SDR_total  = rowSums(across(starts_with("SDR")), na.rm = TRUE),
    NS_sum     = rowSums(across(NS1:NS3), na.rm = TRUE),
    RD_sum     = rowSums(across(RD1:RD3), na.rm = TRUE),
    FRLF_mini  = NS_sum + RD_sum,                               # FR-LF logic (NS + RD)
    KSA_A      = rowSums(across(A1:A3), na.rm = TRUE),
    KSA_U      = rowSums(across(U1:U3), na.rm = TRUE),
    KSA_K      = rowSums(across(K1:K3), na.rm = TRUE),
    KSA_total  = KSA_A + KSA_U + KSA_K
  ) %>%
  # z-standardize predictors for comparability of β
  mutate(across(c(NS_sum, FRLF_mini, KSA_total, KN_total, SDR_total), scale, .names="{.col}_z"))
```

**Interpretation.** If **NS-only** predicts HPT similarly to (or more strongly than) broad authoritarianism (KSA-3), the HPT score may be **ideologically contaminated** by Nazi-congruent attitudes, consistent with our preregistered concern. 

---

# 3. Exclusions: knowledge outliers & extreme SDR

**Rules (predefined here for sensitivity only):**

* **Knowledge outliers:** drop KN totals outside the Tukey fence ([Q_1-1.5,IQR,;Q_3+1.5,IQR]).
* **Extreme SDR:** drop the **top 10%** of SDR totals (possible “faking good”). Codebook notes SDR2–SDR4 are reversed already. 

```{r,exclusion-flags}
# Compute fences
kn_q <- quantile(dat$KN_total, probs = c(.25, .75), na.rm = TRUE)
kn_iqr <- kn_q[2]-kn_q[1]
kn_low <- kn_q[1] - 1.5*kn_iqr
kn_high<- kn_q[2] + 1.5*kn_iqr

sdr_p90 <- quantile(dat$SDR_total, probs = .90, na.rm = TRUE)

dat <- dat %>%
  mutate(
    excl_KN  = KN_total < kn_low | KN_total > kn_high,
    excl_SDR = SDR_total >= sdr_p90,
    keep_all = TRUE,
    keep_excl= !(excl_KN | excl_SDR)
  )

table_excl <- tibble(
  Criterion = c("Total N", "Drop KN outliers", "Drop top-10% SDR", "Kept (both rules)"),
  N = c(nrow(dat),
        sum(dat$excl_KN, na.rm=TRUE),
        sum(dat$excl_SDR, na.rm=TRUE),
        sum(dat$keep_excl, na.rm=TRUE))
)

gt(table_excl) %>%
  tab_header(title="Exclusion counts (for sensitivity runs)")
```

**Interpretation.** If effects persist after dropping **low-knowledge** and **high-SDR** respondents, results are less likely to be artefacts of misunderstanding or impression management.

---

# 4. Mixed models with class clustering & random slopes

We estimate multilevel models (students nested in classes), starting with random intercepts and then allowing the **ideology effect to vary by class**. We fit the models for each **HPT scoring** and **ideology** variant.

```{r,model-funs}
fit_models <- function(data, hpt_var, ideol_var){
  form0 <- as.formula(glue("{hpt_var} ~ {ideol_var} + KN_total_z + SDR_total_z + (1 | class_label)"))
  form1 <- as.formula(glue("{hpt_var} ~ {ideol_var} + KN_total_z + SDR_total_z + (1 + {ideol_var} | class_label)"))
  m0 <- lmer(form0, data = data)
  # Try random slope; if singular, fall back to intercept-only
  m1 <- try(lmer(form1, data = data), silent = TRUE)
  if(inherits(m1,"try-error") || isTRUE(isSingular(m1))) m1 <- NULL
  list(m0=m0, m1=m1)
}

tidy_model <- function(m){
  tibble(
    term   = broom.mixed::tidy(m, effects="fixed")$term,
    estimate = broom.mixed::tidy(m, effects="fixed")$estimate,
    conf.low = confint(m, method="Wald")[names(fixef(m)),1],
    conf.high= confint(m, method="Wald")[names(fixef(m)),2],
    p.value  = broom.mixed::tidy(m, effects="fixed")$p.value,
    R2_marg  = performance::r2_nakagawa(m)$R2_marginal,
    R2_cond  = performance::r2_nakagawa(m)$R2_conditional
  )
}
```

### Run model grid

```{r,run-models, warning=FALSE, message=FALSE}
hpt_vars   <- c("HPT_total_9","HPT_total_8","HPT_total_6")
ideol_vars <- c("NS_sum_z","FRLF_mini_z","KSA_total_z")

# Full sample
grid_full <- expand_grid(hpt=hpt_vars, ideol=ideol_vars) %>%
  mutate(fits = map2(hpt, ideol, ~fit_models(dat %>% filter(keep_all), .x, .y)),
         m0   = map(fits, "m0"),
         m1   = map(fits, "m1"))

# Exclusion sample (drop KN outliers & top-10% SDR)
grid_excl <- expand_grid(hpt=hpt_vars, ideol=ideol_vars) %>%
  mutate(fits = map2(hpt, ideol, ~fit_models(dat %>% filter(keep_excl), .x, .y)),
         m0   = map(fits, "m0"),
         m1   = map(fits, "m1"))
```

### Summaries (key coefficient = ideology)

```{r,summarise-models}
summarise_grid <- function(grid, label){
  out0 <- grid %>%
    mutate(tidy0 = map(m0, tidy_model)) %>%
    unnest(tidy0) %>%
    filter(term == "(Intercept)" | str_detect(term, "NS_sum_z|FRLF_mini_z|KSA_total_z")) %>%
    select(hpt, ideol, term, estimate, conf.low, conf.high, p.value, R2_marg, R2_cond) %>%
    mutate(model = "RI") # random intercept

  out1 <- grid %>%
    filter(!map_lgl(m1, is.null)) %>%
    mutate(tidy1 = map(m1, tidy_model)) %>%
    unnest(tidy1) %>%
    filter(term == "(Intercept)" | str_detect(term, "NS_sum_z|FRLF_mini_z|KSA_total_z")) %>%
    select(hpt, ideol, term, estimate, conf.low, conf.high, p.value, R2_marg, R2_cond) %>%
    mutate(model = "RS") # random slope (ideology)

  bind_rows(out0, out1) %>% mutate(sample = label)
}

tab_full <- summarise_grid(grid_full, "Full")
tab_excl <- summarise_grid(grid_excl, "Exclusions applied")

tab_models <- bind_rows(tab_full, tab_excl) %>%
  mutate(ideol = recode(ideol,
                        NS_sum_z="NS (z)", FRLF_mini_z="FR-LF: RD+NS (z)", KSA_total_z="KSA-3 total (z)"),
         hpt   = recode(hpt,
                        HPT_total_9="HPT 9-item", HPT_total_8="HPT 8-item (drop ROA1)",
                        HPT_total_6="HPT 6-item (no ROA)")) %>%
  arrange(sample, hpt, ideol, model)
```

```{r,print-models}
tab_models %>%
  mutate(across(c(estimate, conf.low, conf.high, R2_marg, R2_cond), ~round(., 3)),
         p.value = signif(p.value, 3)) %>%
  gt() %>%
  tab_header(title="Multilevel models: ideology → HPT (controls: KN, SDR; class clustered)") %>%
  tab_spanner(label = "Effect (β and 95% CI)", columns = c(estimate, conf.low, conf.high)) %>%
  cols_label(sample="Sample", hpt="HPT score", ideol="Ideology", model="Model",
             estimate="β", conf.low="CI low", conf.high="CI high",
             p.value="p", R2_marg="R² (marg.)", R2_cond="R² (cond.)")
```

**How to read the table.**

* **Rows** = combinations of HPT scoring (9/8/6 items), ideology metric (NS only; FR-LF RD+NS; KSA-3), and model type:
  **RI** = random-intercept by class; **RS** = also random **slope** of ideology by class (shown only when not singular).
* **Key cell** = the **β for ideology** (standardised), with **95% CI**.
* **R² (marg./cond.)** give variance explained by fixed effects and by full model.

**Interpretation guide.**

* If **NS (z)** predicts HPT strongly while KSA-3 does not, HPT may be **aligned with Nazi-congruent content** rather than general authoritarianism—i.e., content **congruence** instead of better historical reasoning. This is the contamination mechanism we flagged. 
* If effects are **stable across 9/8/6-item** HPT scores, conclusions are **robust** to ROA decisions. If they require ROA to appear, caution is warranted given prior ROA instability. 
* If **random slopes** improve fit (higher R²_cond; non-singular), the ideology–HPT link **varies by class**. That suggests classroom climate/teaching may moderate how ideology maps onto HPT.

---

# 5. Sanity checks & clarity plots (optional quick look)

```{r,quick-plots, fig.width=8, fig.height=5}
dat %>%
  ggplot(aes(NS_sum, HPT_total_9)) +
  geom_point(alpha=.3) + geom_smooth(method="lm", se=TRUE) +
  labs(x="NS (sum)", y="HPT total (9-item)",
       title="Bivariate check (unadjusted): NS vs. HPT") +
  theme(plot.title.position="plot")
```

**Interpretation.** These quick plots are only to **visualise direction**; final inferences come from the multilevel models with controls.

---

# 6. Read-outs you can cite in prose

* **Stable conclusions** across HPT **9/8/6** scoring → results **do not depend** on ROA items. (ROA instability has been noted previously.) 
* **NS-only** predicting as much/more than **KSA-3** → supports the **ideological contamination** concern in our PCI RR snapshot. 
* Survives **knowledge/SDR exclusions** → less likely driven by misunderstanding or impression management; SDR handling follows our codebook. 
* **Random slopes needed** → ideology effects differ **by class**, implying a pedagogical moderation worth exploring (teaching of context vs. presentism etc.), in line with the HPT literature’s emphasis on contextual frames. 

---

# Reproducibility appendix

```{r,session-info}
sessionInfo()
```